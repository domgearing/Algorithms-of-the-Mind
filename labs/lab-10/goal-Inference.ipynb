{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b223ac",
   "metadata": {},
   "source": [
    "# Goal inference via Bayesian Inverse Planning\n",
    "\n",
    "This lab section is based on [this](https://www.gen.dev/tutorials/data-driven-proposals/tutorial) offical Gen tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ff00a",
   "metadata": {},
   "source": [
    "We will start by introducing a probabilistic model for the motion of an autonomous agent. The model itself demonstrates an important feature of Gen: because it is embedded in Julia, we can use complex, black-box programs as sub-routines in our models. The model we develop here uses an _RRT path planner_ (a variant of the famous A-star planning algorithm) to model the goal-directed motion of the agent.\n",
    "\n",
    "We then invert this generative model, given a sequence of actions of the agent, to infer their goal location. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f970a",
   "metadata": {},
   "source": [
    "This tutorial will also illustrate **learning to do inference** with a neural network, by combining a data-driven proposal with importance sampling. In particular, we learn to make data-driven proposals about where the goal location is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56602920",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c5c83",
   "metadata": {},
   "source": [
    "**Section 1.** [A generative model of an autonomous agent](#model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f7917",
   "metadata": {},
   "source": [
    "**Section 2.** [Writing a data-driven proposal as a generative function](#custom-proposal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120360aa",
   "metadata": {},
   "source": [
    "**Section 3.** [Using a data-driven proposal within importance sampling](#using)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52280133",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**Section 4.** [Training the parameters of a data-driven proposal](#training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this block can take a few minutes to run\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(\"lab10\")\n",
    "Pkg.add([\"Distributions\", \"Luxor\", \"Plots\", \"JLD2\", \"Gen\"])\n",
    "using Distributions\n",
    "using Luxor\n",
    "using Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5c372",
   "metadata": {},
   "source": [
    "## 1: A generative model of an autonomous agent   <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d29c88",
   "metadata": {},
   "source": [
    "We begin by writing a generative probabilistic model of the motion of an\n",
    "intelligent agent that is navigating a two-dimensional maze-like scene. \n",
    "The model will invoke a path planning algorithm (implemented in\n",
    "regular Julia code) to generate the agent's motion plan from its destination\n",
    "and its map of the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5a9ca",
   "metadata": {},
   "source": [
    "First, we load some basic geometric primitives for a two-dimensional scene. We\n",
    "implemented these already in an auxiliary Julia file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./utils/geometric_primitives.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485599c7",
   "metadata": {},
   "source": [
    "The file we loaded gives us the `Point` data type (imported from [Luxor.jl](https://juliagraphics.github.io/Luxor.jl/)), which has fields `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26959159",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = Point(1.0, 2.0)\n",
    "println(point.x)\n",
    "println(point.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634459e",
   "metadata": {},
   "source": [
    "The file also defines an `Obstacle` data type, which represents a polygonal\n",
    "obstacle in a two-dimensional scene, that is constructed from a list of\n",
    "vertices. Here, we construct a square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ac961",
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacle = Obstacle([Point(0.0, 0.0), Point(0.5, 0.0), Point(0.5, 1.0), Point(0.0, 1.0)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5f4ff",
   "metadata": {},
   "source": [
    "Next, we load the definition of a `Scene` data type that represents a\n",
    "two-dimensional scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd82ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./utils/scene.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccfad1",
   "metadata": {},
   "source": [
    "The `Scene` data type represents a rectangle on the two-dimensional x-y plane\n",
    "with a list of obstacles, which is initially empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ee71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = Scene(xmin=0, xmax=1, ymin=0, ymax=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1cc4a6",
   "metadata": {},
   "source": [
    "Obstacles can be added to a scene with the `add_obstacle!` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_obstacle!(scene, obstacle);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61744927",
   "metadata": {},
   "source": [
    "The file we imported also defines functions that simplify the construction of obstacles:\n",
    "\n",
    "`make_square(center::Point, size::Float64)` constructs a square-shaped\n",
    "obstacle centered at the given point with the given side length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_obstacle = make_square(Point(.25, .75), 0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8940fafb",
   "metadata": {},
   "source": [
    "`make_line(vertical::Bool, start::Point, length::Float64,\n",
    "thickness::Float64)` constructs an axis-aligned line (either vertical or\n",
    "horizontal) with given thickness that extends from a given strating point for\n",
    "a certain length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_wall_obstacle = make_line(false, Point(0.20, 0.40), 0.40, 0.02);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9d05a",
   "metadata": {},
   "source": [
    "We now construct a scene value that we will use in the rest of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = Scene(xmin=0, xmax=1, ymin=0, ymax=1)\n",
    "add_obstacle!(scene, make_square(Point(0.30, 0.20), 0.1))\n",
    "add_obstacle!(scene, make_square(Point(0.83, 0.80), 0.1))\n",
    "add_obstacle!(scene, make_square(Point(0.80, 0.40), 0.1))\n",
    "horizontal = false\n",
    "vertical = true\n",
    "wall_thickness = 0.02\n",
    "add_obstacle!(scene, make_line(horizontal, Point(0.20, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_line(vertical, Point(0.60, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_line(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene, make_line(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))\n",
    "add_obstacle!(scene, make_line(vertical, Point(0.20, 0.40), 0.40, wall_thickness));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd74b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We visualize the scene below.\n",
    "include(\"./utils/viz.jl\")\n",
    "visualize() do\n",
    "    draw_scene(scene)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b87694",
   "metadata": {},
   "source": [
    "Next, we load a file that defines a `Path` data type (a sequence of\n",
    "`Point`s), and a `plan_path` method, which  uses a path planning algorithm\n",
    "based on rapidly exploring random tree (RRT, [1]) to find a sequence of\n",
    "`Point`s beginning with `start` and ending in `dest` such that the line\n",
    "segment between each consecutive pair of points does not intersect any\n",
    "obstacles in the scene. The planning algorithm may fail to find a valid path,\n",
    "in which case it will return a value of type `Nothing`.\n",
    "\n",
    "`path::Union{Path,Nothing} = plan_path(start::Point, dest::Point,\n",
    "scene::Scene, planner_params::PlannerParams)`\n",
    "\n",
    "[1] [_Rapidly-exploring random trees: A new tool for path planning._](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.1853&rep=rep1&type=pdf)\n",
    "S. M. LaValle. TR 98-11, Computer Science Dept., Iowa State University, October 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./utils/planning.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970181c",
   "metadata": {},
   "source": [
    "Let's use `plan_path` to plan a path from the lower-left corner of the scene\n",
    "into the interior of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1902a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "dest = Point(0.5, 0.5)\n",
    "planner_params = PlannerParams(rrt_iters=600, rrt_dt=3.0,\n",
    "                               refine_iters=3500, refine_std=1.)\n",
    "example_path = plan_path(start, dest, scene, planner_params);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032fa19",
   "metadata": {},
   "source": [
    "We visualize the path below with the function `visualize` (defined in the\n",
    "external file we loaded), which will visualize the path in the scene.\n",
    "The start location is shown as a blue circle, the\n",
    "destination as a red rhombus, and the path in orange. Run the cell above followed by\n",
    "the cell below a few times to see the variability in the paths generated by\n",
    "`plan_path` for these inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize() do\n",
    "    draw_trace(Dict(:start => start,\n",
    "                    :dest => dest,\n",
    "                    :scene => scene,\n",
    "                    :path => example_path.points);\n",
    "               should_draw_measurements=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65721fc4",
   "metadata": {},
   "source": [
    "We also need a model for how the agent moves along its path.\n",
    "We will assume that the agent moves along its path a constant speed. The file\n",
    "loaded above also defines a method `walk_path(path, speed, dt, num_ticks)` \n",
    "that computes the locations of the agent at a set of timepoints \n",
    "(a vector of `Point`s sampled at time intervals of `dt` starting at time `0.`),\n",
    "given the path and the speed of the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb85051",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = 1.\n",
    "dt = 0.1\n",
    "num_ticks = 10;\n",
    "example_locations = walk_path(example_path, speed, dt, num_ticks)\n",
    "println(example_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031255eb",
   "metadata": {},
   "source": [
    "Now, we are prepated to write our generative model for the motion of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f82872",
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function agent_model(\n",
    "        scene::Scene, dt::Float64, num_ticks::Int, \n",
    "        planner_params::PlannerParams)\n",
    "\n",
    "    # sample the start point of the agent from the prior\n",
    "    start_x ~ uniform(0, 1)\n",
    "    start_y ~ uniform(0, 1)\n",
    "    start = Point(start_x, start_y)\n",
    "\n",
    "    # sample the destination point of the agent from the prior\n",
    "    dest_x ~ uniform(0, 1)\n",
    "    dest_y ~ uniform(0, 1)\n",
    "    dest = Point(dest_x, dest_y)\n",
    "\n",
    "    # plan a path that avoids obstacles in the scene\n",
    "    maybe_path = plan_path(start, dest, scene, planner_params)\n",
    "    planning_failed = maybe_path === nothing\n",
    "    \n",
    "    # sample the speed from the prior\n",
    "    speed ~ uniform(0.3, 1)\n",
    "\n",
    "    if planning_failed   \n",
    "        # path planning failed; assume agent stays at start location indefinitely\n",
    "        locations = fill(start, num_ticks)\n",
    "    else   \n",
    "        # path planning succeeded; move along the path at constant speed\n",
    "        locations = walk_path(maybe_path, speed, dt, num_ticks)\n",
    "    end\n",
    "\n",
    "    # generate noisy measurements of the agent's location at each time point\n",
    "    noise = 0.01\n",
    "    for (i, point) in enumerate(locations)\n",
    "        x = {:meas => (i, :x)} ~ normal(point.x, noise)\n",
    "        y = {:meas => (i, :y)} ~ normal(point.y, noise)\n",
    "    end\n",
    "\n",
    "    return (planning_failed, maybe_path)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ba644",
   "metadata": {},
   "source": [
    "We can now perform a traced execution of `agent_model` and examine the\n",
    "random choices it made:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf4a17",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Using `simulate` (or `generate`, without any constraints) to sample a trace,\n",
    "get the random choices made by this model. Parameterize the planner using\n",
    "`PlannerParams` with the same parameters as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe18b3d",
   "metadata": {},
   "source": [
    "<!-- # BEGIN ANSWER KEY 2A.1\n",
    "\n",
    "planner_params = PlannerParams(rrt_iters=600, rrt_dt=3.0,\n",
    "                               refine_iters=3500, refine_std=1.)\n",
    "trace = Gen.simulate(agent_model, (scene, dt, num_ticks, planner_params));\n",
    "choices = Gen.get_choices(trace)\n",
    "display(choices)\n",
    "\n",
    "# END ANSWER KEY -->\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea99e02",
   "metadata": {},
   "source": [
    "Next we explore the assumptions of the model by sampling many traces from the\n",
    "generative function and visualizing them. We have created a visualization\n",
    "specialized for this generative function in the file we included above.\n",
    "It also defined a `visualize_grid` method to plot traces in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0427d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize several traces of the function, with the start location fixed to\n",
    "# a point in the lower-left corner:\n",
    "constraints = Gen.choicemap()\n",
    "constraints[:start_x] = 0.1\n",
    "constraints[:start_y] = 0.1\n",
    "\n",
    "traces = [Gen.generate(\n",
    "    agent_model, (scene, dt, num_ticks, planner_params), constraints\n",
    "    )[1] for i in 1:12];\n",
    "visualize_grid(traces, 4, 600; separators=\"gray\") do trace, frame\n",
    "    draw_trace(trace, frame; draw_measurements=true, markersize=6)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df153f9",
   "metadata": {},
   "source": [
    "In this visualization, the measured coordinates at each\n",
    "time point are represented by black $\\times$ marks. The path, if path planning was\n",
    "succesful, is shown as an orange line from the start point to the destination\n",
    "point. Notice that the speed of the agent is different in each case. Also note that\n",
    "the we observe the agent for a fixed amount of time, in which they may or may not\n",
    "finish walking their planned path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17220d19",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Edit the constraints passed to the inference algorithm:\n",
    "\n",
    "1. Constrain the start of the agent to be at $x = 0.9$, $y = 0.1$.\n",
    "2. Constrain the destination of the agent to be at $x = 0.9$, $y = 0.8$.\n",
    "\n",
    "\n",
    "Visualize the resulting prior. We have provided some starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# < put your code here>\n",
    "traces_constrained = []\n",
    "for i in 1:12\n",
    "    # Modify the following line:\n",
    "    (trace_constrained, _) = Gen.generate(agent_model, (scene, dt, num_ticks, planner_params))\n",
    "    push!(traces_constrained, trace_constrained)\n",
    "end\n",
    "\n",
    "# Visualize:\n",
    "visualize_grid(traces_constrained, 4, 600; separators=\"gray\") do trace, frame\n",
    "    draw_trace(trace, frame; draw_measurements=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de2189",
   "metadata": {},
   "source": [
    "<!-- # BEGIN ANSWER KEY 2A.2\n",
    "\n",
    "constraints = Gen.choicemap()\n",
    "constraints[:start_x] = 0.9\n",
    "constraints[:start_y] = 0.1\n",
    "\n",
    "constraints[:dest_x] = 0.9\n",
    "constraints[:dest_y] = 0.8\n",
    "\n",
    "traces_constrained = []\n",
    "for i in 1:12\n",
    "    # Modify the following line:\n",
    "    (trace_constrained, _) = Gen.generate(agent_model, (scene, dt, num_ticks, planner_params), constraints)\n",
    "    push!(traces_constrained, trace_constrained)\n",
    "end\n",
    "\n",
    "# Visualize:\n",
    "visualize_grid(traces_constrained, 4, 600; separators=\"gray\") do trace, frame\n",
    "    draw_trace(trace, frame; draw_measurements=true)\n",
    "end\n",
    "\n",
    "# END ANSWER KEY -->\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c0497",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "The `rrt_iters` field of `PlannerParams` is the number of iterations of the RRT\n",
    "algorithm to use. The `refine_iters` field of `PlannerParams` is the number of\n",
    "iterations of path refinement. These parameters affect the distribution on\n",
    "paths of the agent. Visualize traces of the `agent_model` with a couple of\n",
    "different settings of these two parameters to the path planning algorithm for\n",
    "fixed starting point and destination point. Try setting them to smaller\n",
    "values. Discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e49f0",
   "metadata": {},
   "source": [
    "We have provided starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = Gen.choicemap()\n",
    "constraints[:start_x] = 0.1\n",
    "constraints[:start_y] = 0.1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231142c",
   "metadata": {},
   "source": [
    "Modify the `PlannerParams` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_params = PlannerParams(\n",
    "    rrt_iters=300, rrt_dt=3.0, refine_iters=2000, refine_std=1.) # < change this line>\n",
    "\n",
    "traces = [Gen.generate(agent_model, (scene, dt, num_ticks, planner_params), constraints)[1] for i in 1:12];\n",
    "visualize_grid(traces, 4, 600; separators=\"gray\") do trace, frame \n",
    "    draw_trace(trace, frame; draw_measurements=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1b41",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15fc33",
   "metadata": {},
   "source": [
    "For the next few sections of the notebook, let's reset any variables that may have changed during your exploration with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "dt = 0.1\n",
    "num_ticks = 10\n",
    "planner_params = PlannerParams(rrt_iters=600, rrt_dt=3.0,\n",
    "                               refine_iters=3500, refine_std=1.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46126cc",
   "metadata": {},
   "source": [
    "We will infer the destination of the agent for the given sequence of observed locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = [\n",
    "    Point(0.0980245, 0.104775),\n",
    "    Point(0.113734, 0.150773),\n",
    "    Point(0.100412, 0.195499),\n",
    "    Point(0.114794, 0.237386),\n",
    "    Point(0.0957668, 0.277711),\n",
    "    Point(0.140181, 0.31304),\n",
    "    Point(0.124384, 0.356242),\n",
    "    Point(0.122272, 0.414463),\n",
    "    Point(0.124597, 0.462056),\n",
    "    Point(0.126227, 0.498338)];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd285b2a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Run inference using Gen's built-in importance resampling implementation. Use\n",
    "50 importance samples (`amt_computation`). \n",
    "\n",
    "To see how to use the built-in importance resampling function, run\n",
    "```?Gen.importance_resampling``` or check out the\n",
    "[documentation](https://www.gen.dev/docs/dev/ref/importance/#Gen.importance_resampling).\n",
    "\n",
    "You can also consult earlier lab sections -- e.g., lab section 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e2d6c",
   "metadata": {},
   "source": [
    "We have provided some starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0873ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference(\n",
    "        scene::Scene, dt::Float64, num_ticks::Int, \n",
    "        planner_params::PlannerParams, \n",
    "        start::Point, measurements::Vector{Point}, amount_of_computation::Int)\n",
    "    \n",
    "    # Constrain the observed measurements.\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => (i, :x)] = m.x\n",
    "        observations[:meas => (i, :y)] = m.y\n",
    "    end\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return trace\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e07e2",
   "metadata": {},
   "source": [
    "<!-- # BEGIN ANSWER KEY 2A.3\n",
    "\n",
    "function do_inference(\n",
    "        scene::Scene, dt::Float64, num_ticks::Int, \n",
    "        planner_params::PlannerParams, \n",
    "        start::Point, measurements::Vector{Point}, amount_of_computation::Int)\n",
    "    \n",
    "    # Constrain the observed measurements.\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => (i, :x)] = m.x\n",
    "        observations[:meas => (i, :y)] = m.y\n",
    "    end\n",
    "    \n",
    "    # Call importance_resampling to obtain a likely trace consistent\n",
    "    # with our observations.\n",
    "    (trace, _) = Gen.importance_resampling(\n",
    "        agent_model, (scene, dt, num_ticks, planner_params),\n",
    "        observations, amount_of_computation)\n",
    "    \n",
    "    return trace\n",
    "end;\n",
    "\n",
    "# END ANSWER KEY -->\n",
    "#### Visualize your answer\n",
    "Below, we run this algorithm 500 times, to generate 500 approximate samples\n",
    "from the posterior distribution on the destination. The inferred destinations\n",
    "should appear as red rhombuses on the map. The following function\n",
    "visualizes the paths overlaid on the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function visualize_inference(measurements, scene, start; computation_amt=50, samples=1000)\n",
    "    visualize() do\n",
    "        for i in 1:samples\n",
    "            trace = do_inference(scene, dt, num_ticks, planner_params, start, measurements, computation_amt)\n",
    "            draw_trace(trace; draw_measurements=true, draw_path=false)\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4856244",
   "metadata": {},
   "source": [
    "\n",
    "And now we run it! Note that this might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_inference(\n",
    "    measurements, scene, start, computation_amt=100, samples=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c6834",
   "metadata": {},
   "source": [
    "The algorithm has made reasonable inferences about where the agent was likely\n",
    "trying to go."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33551e",
   "metadata": {},
   "source": [
    "Note that the above illustration takes a while to produce. This is\n",
    "because computing each endpoint requires sampling 100 times from the default proposal (which\n",
    "runs the RRT planner). When our models contain more expensive components, like\n",
    "the path-planner, the computational demands of inference increase accordingly.\n",
    "This motivates us to find more efficient inference algorithms, that will\n",
    "require fewer model evaluations to produce good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a7baf",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6fc959",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65029d4",
   "metadata": {},
   "source": [
    "In this problem, you'll explore the effect of changing the _scene_ on the\n",
    "inferences we make about the agent. Below, we've reproduced the code for\n",
    "constructing the scene in which we performed inference above. Modify the scene\n",
    "so that there is an opening into the \"room\" along the _bottom_ wall, in\n",
    "addition to the already-existing door along top wall. Otherwise, the scene\n",
    "should be identical to the one above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d428e3",
   "metadata": {},
   "source": [
    "Rerun inference. The results should be qualitatively different from the\n",
    "results generated above, even though the observed movements of the agent are\n",
    "identical. **Write a one- or two-sentence description of how the results are\n",
    "different, and why.** Please address:\n",
    "\n",
    "1. Why would a _human_ make different inferences about the agent's likely\n",
    "   destination in the two different scenes?\n",
    "2. To what extent does the _model_ succeed in producing qualitiatively\n",
    "   different results in the two scenes? Why? (Concretely, why are certain\n",
    "   proposals more often rejected by importance sampling in the two-door scene\n",
    "   than in the one-door scene?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dbd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_2doors = Scene(xmin=0, xmax=1, ymin=0, ymax=1)\n",
    "\n",
    "# Add the three blocks.\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.30, 0.20), 0.1))\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.83, 0.80), 0.1))\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.80, 0.40), 0.1))\n",
    "\n",
    "# Add the walls. You will need to change this code. In particular, you will need to edit \n",
    "# one of these lines (the one that constructs the bottom wall of the room) and add one new line\n",
    "# (because in order to create the \"door\", you will actually need to represent the bottom wall\n",
    "# as two separate rectangular obstacles -- as the sample code already does for the top wall).\n",
    "horizontal = false\n",
    "vertical = true\n",
    "wall_thickness = 0.02\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(vertical, Point(0.60, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(vertical, Point(0.20, 0.40), 0.40, wall_thickness));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63dfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform and visualize inference:\n",
    "visualize_inference(measurements, scene_2doors, start, computation_amt=100, samples=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a19556",
   "metadata": {},
   "source": [
    "**Free response:** What changed about the inferences when you changed the scene,\n",
    "and why? You might address:\n",
    "\n",
    "1. Why would a _human_ make different inferences about the agent's likely\n",
    "   destination in the two different scenes?\n",
    "2. To what extent does the _model_ succeed in producing qualitiatively\n",
    "   different results in the two scenes? (Concretely, why are certain proposals\n",
    "   more often rejected by importance sampling in the two-door scene than in\n",
    "   the one-door scene?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6f1f6",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<!-- # BEGIN ANSWER KEY 2.4\n",
    "\n",
    "scene_2doors = Scene(xmin=0, xmax=1, ymin=0, ymax=1)\n",
    "\n",
    "# Add the three blocks.\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.30, 0.20), 0.1))\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.83, 0.80), 0.1))\n",
    "add_obstacle!(scene_2doors, make_square(Point(0.80, 0.40), 0.1))\n",
    "\n",
    "horizontal = false\n",
    "vertical = true\n",
    "wall_thickness = 0.02\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.60 - 0.15, 0.40), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.40), 0.15, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(vertical, Point(0.60, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))\n",
    "add_obstacle!(scene_2doors, make_line(vertical, Point(0.20, 0.40), 0.40, wall_thickness))\n",
    "\n",
    "# Perform and visualize inference:\n",
    "visualize_inference(measurements, scene_2doors, start, computation_amt=50, samples=100)\n",
    "\n",
    "# END ANSWER KEY -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ffcc7e",
   "metadata": {},
   "source": [
    "## 2. Writing a data-driven proposal as a generative function <a name=\"custom-proposal\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba66f6",
   "metadata": {},
   "source": [
    "The inference algorithm above used a variant of\n",
    "[`Gen.importance_resampling`](https://probcomp.github.io/Gen/dev/ref/importance/#Gen.importance_resampling)\n",
    "that does not take a custom proposal distribution. It uses the default\n",
    "proposal distribution associated with the generative model. For generative\n",
    "functions defined using the built-in modeling DSL, the default proposal\n",
    "distribution is based on *ancestral sampling*, which involves sampling\n",
    "unconstrained random choices from the distributions specified in the\n",
    "generative model. Put more simply, each \"guess\" the inference algorithm\n",
    "makes about the possible destination of the agent is totally uninformed\n",
    "by the observed measurements; it is sampled using the prior generative\n",
    "model's `dest_x` and `dest_y` sampling statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a0496",
   "metadata": {},
   "source": [
    "We can visualize this default proposal distribution by sampling from it, \n",
    "using `Gen.generate` (note, we also could use `Gen.simulate` for the same purpose, since we are not passing any constraints). The cell below shows samples of the agent's destination \n",
    "drawn from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"./utils/viz.jl\");\n",
    "\n",
    "traces = [Gen.generate(agent_model, (scene, dt, num_ticks, planner_params))[1] for i in 1:1000]\n",
    "visualize() do\n",
    "\n",
    "    for i in 1:1000\n",
    "        trace, = Gen.generate(agent_model, (scene, dt, num_ticks, planner_params))\n",
    "        draw_dest(scene, Point(trace[:dest_x], trace[:dest_y]))\n",
    "    end\n",
    "\n",
    "    draw_scene(scene)\n",
    "    draw_start(scene, start)\n",
    "    draw_measurements(scene, measurements)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e7671",
   "metadata": {},
   "source": [
    "Intuitively, if we see the data set above (where blue is the starting\n",
    "location, and the measurements are in black), we might guess that the \n",
    "agent is more likely to be heading into the upper part of the scene. This \n",
    "is because we don't expect the agent to unecessarily backtrack on its route\n",
    "to its destnation. A simple heuristic for biasing the proposal distribution \n",
    "of the destination using just the first measurement and the last measurement might be:\n",
    "\n",
    "- If the x-coordinate of the last measurement is greater than the\n",
    "  x-coordinate of the first measurement, we think the agent is probably\n",
    "  headed generally to the right. Make values `:dest_x` that are greater than\n",
    "  the x-coordinate of the last measurement more probable.\n",
    "\n",
    "- If the x-coordinate of the last measurment is less than the x-coordinate of\n",
    "  the first measurement, we think the agent is probably headed generally to\n",
    "  the left. Make values  `:dest_x` that are smaller than the x-coordinate of\n",
    "  the last measurement more probable.\n",
    "\n",
    "We can apply the same heuristic separately for the y-coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1add8c",
   "metadata": {},
   "source": [
    "To implement this idea, we discretize the x-axis and y-axis of the scene into\n",
    "bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x_bins = 5\n",
    "num_y_bins = 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c08c56",
   "metadata": {},
   "source": [
    "We will propose the x-coordinate of the destination from a\n",
    "[piecewise_uniform](https://www.gen.dev/docs/dev/ref/distributions/#Gen.piecewise_uniform)\n",
    "distribution, where we set higher probability for certain bins based on the\n",
    "heuristic described above and use a uniform continuous distribution for the\n",
    "coordinate within a bin. The `compute_bin_probs` function below computes the\n",
    "probability for each bin. The bounds of the scene are given by `min` and\n",
    "`max`. The coordinates of the first and last measured points respectively are\n",
    "given by `first` and `last`. We compute the probability by assigning a\n",
    "\"score\" to each bin based on the heuristic above --- if the bin should\n",
    "receive lower probability, it gets a score of 1., and if it should receive\n",
    "higher probability, it gets a bin of `score_high`, where `score_high` is some\n",
    "value greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_bin_prob(first::Float64, last::Float64, bin::Int, last_bin::Int, score_high)\n",
    "    last >= first && bin >= last_bin && return score_high\n",
    "    last < first && bin <= last_bin && return score_high\n",
    "    return 1.\n",
    "end\n",
    "\n",
    "function compute_bin_probs(num_bins::Int, min::Float64, max::Float64, first::Float64, last::Float64, score_high)\n",
    "    bin_len = (max - min) / num_bins\n",
    "    last_bin = Int(floor(last / bin_len)) + 1\n",
    "    probs = [compute_bin_prob(first, last, bin, last_bin, score_high) for bin=1:num_bins]\n",
    "    total = sum(probs)\n",
    "    return [p / total for p in probs]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75dbd8",
   "metadata": {},
   "source": [
    "We will see how to automatically tune the value of `score_high` shortly. For\n",
    "now, we will use a value of 5. Below, we see that for the data set of\n",
    "measurements, shown above the probabilities of higher bins are indeed 5x\n",
    "larger than those of lower bins, becuase the agent seems to be headed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bin_probs(num_y_bins, scene.ymin, scene.ymax, measurements[1].y, measurements[end].y, 5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25912b7d",
   "metadata": {},
   "source": [
    "Next, we write a generative function that applies this heuristic for both the\n",
    "x-coordinate and y-coordinate, and samples the destination coordinates at\n",
    "addresses `:dest_x` and `:dest_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae751ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function custom_dest_proposal(measurements::Vector{Point}, scene::Scene)\n",
    "\n",
    "    score_high = 5.\n",
    "    \n",
    "    x_first = measurements[1].x\n",
    "    x_last = measurements[end].x\n",
    "    y_first = measurements[1].y\n",
    "    y_last = measurements[end].y\n",
    "    \n",
    "    # sample dest_x\n",
    "    x_probs = compute_bin_probs(num_x_bins, scene.xmin, scene.xmax, x_first, x_last, score_high)\n",
    "    x_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_x_bins+1))\n",
    "    dest_x ~ piecewise_uniform(x_bounds, x_probs)\n",
    "    \n",
    "    # sample dest_y\n",
    "    y_probs = compute_bin_probs(num_y_bins, scene.ymin, scene.ymax, y_first, y_last, score_high)\n",
    "    y_bounds = collect(range(scene.ymin, stop=scene.ymax, length=num_y_bins+1))\n",
    "    dest_y ~ piecewise_uniform(y_bounds, y_probs)\n",
    "    \n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0655a",
   "metadata": {},
   "source": [
    "We can propose values of random choices from the proposal function using\n",
    "[`Gen.propose`](https://probcomp.github.io/Gen/dev/ref/gfi/#Gen.propose).\n",
    "This method returns the choices, as well as some other information, which we\n",
    "won't need for our purposes. For now, you can think of `Gen.propose` as\n",
    "similar to `Gen.generate` except that it does not produce a full execution\n",
    "trace (only the choices), and it does not accept constraints. We can see the\n",
    "random choices for one run of the proposal on our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfe7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(proposed_choices, _, _) = Gen.propose(custom_dest_proposal, (measurements, scene))\n",
    "proposed_choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd72cfd",
   "metadata": {},
   "source": [
    "The function below runs the proposal 1000 times. For each run, it generates a\n",
    "trace of the model where the `:dest_x` and `:dest_y` choices are constrained\n",
    "to the proposed values, and then visualizes the resulting traces. We make the\n",
    "proposal a parameter of the function because we will be visualizing the\n",
    "output distribution of various proposals later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function visualize_custom_destination_proposal(measurements, start, dest_proposal; num_samples=100)\n",
    "    visualize() do \n",
    "        for i=1:num_samples\n",
    "            (proposed_choices, _) = Gen.propose(dest_proposal, (measurements, scene))\n",
    "            constraints = choicemap(proposed_choices)\n",
    "            constraints[:start_x] = start.x\n",
    "            constraints[:start_y] = start.y\n",
    "            (trace, _) = Gen.generate(agent_model, (scene, dt, num_ticks, planner_params), constraints)\n",
    "            draw_dest(scene, Point(trace[:dest_x], trace[:dest_y]))\n",
    "        end\n",
    "        draw_scene(scene)\n",
    "        draw_start(scene, start)\n",
    "        draw_measurements(scene, measurements)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae8318",
   "metadata": {},
   "source": [
    "Let's visualize the output distribution of `custom_dest_proposal` for our\n",
    "data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ecf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_custom_destination_proposal(measurements, start, custom_dest_proposal, num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869cd30",
   "metadata": {},
   "source": [
    "We see that the proposal distribution indeed samples destinations in the top\n",
    "half of the scene with higher probability than destinations in the bottom\n",
    "half."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c55ac",
   "metadata": {},
   "source": [
    "Alone, this is just a heuristic. But we can use it as a proposal for importance sampling, turning it into an asymptotically valid Bayesian inference algorithm. Alternatively, we can view it as a tool for speeding up our naive importance sampler, by focusing computation on regions of the space that are more likely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47faff",
   "metadata": {},
   "source": [
    "## 3. Using a data-driven proposal within importance sampling <a name=\"using\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bba213",
   "metadata": {},
   "source": [
    "We now use our data-driven proposal within an inference algorithm. There is a\n",
    "second variant of\n",
    "[`Gen.importance_resampling`](https://probcomp.github.io/Gen/dev/ref/importance/#Gen.importance_resampling)\n",
    "that accepts a generative function representing a custom proposal. This\n",
    "proposal generative function makes traced random choices at the addresses of\n",
    "a subset of the unobserved random choices made by the generative model. In\n",
    "our case, these addresses are `:dest_x` and `:dest_y`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b63b49",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Implement an inference program that uses this second variant of importance resampling. \n",
    "\n",
    "\n",
    "Because we will experiment with different data-driven proposals, we make the\n",
    "proposal into an agument of our inference program. We assume that the\n",
    "proposal accepts arguments `(measurements, scene)`.\n",
    "\n",
    "This time, use only 5 importance samples (`amt_computation`). You can run\n",
    "`?Gen.importance_resampling` or check out the\n",
    "[documentation](https://www.gen.dev/docs/stable/ref/inference/importance/#Gen.importance_resampling)\n",
    "to understand how to supply the arguments to invoke this second version of of\n",
    "importance resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bdd72a",
   "metadata": {},
   "source": [
    "We have provided some starter code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference_data_driven(\n",
    "        dest_proposal::GenerativeFunction,\n",
    "        scene::Scene, dt::Float64,\n",
    "        num_ticks::Int, planner_params::PlannerParams,\n",
    "        start::Point, measurements::Vector{Point}, \n",
    "        amount_of_computation::Int)\n",
    "    \n",
    "    observations = Gen.choicemap((:start_x, start.x), (:start_y, start.y))\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => (i, :x)] = m.x\n",
    "        observations[:meas => (i, :y)] = m.y\n",
    "    end\n",
    "    \n",
    "    # trace = ... < put your code here>\n",
    "\n",
    "    return trace\n",
    "end;\n",
    "\n",
    "function visualize_data_driven_inference(measurements, scene, start, proposal; amt_computation=50, samples=1000)\n",
    "    visualize() do \n",
    "      for i=1:samples\n",
    "          trace = do_inference_data_driven(proposal, \n",
    "              scene, dt, num_ticks, planner_params, start, measurements, amt_computation)\n",
    "          draw_dest(scene, Point(trace[:dest_x], trace[:dest_y]))\n",
    "      end\n",
    "        draw_scene(scene)\n",
    "        draw_start(scene, start)\n",
    "        draw_measurements(scene, measurements)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(measurements, scene, start, custom_dest_proposal; amt_computation=5, samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b66ff02",
   "metadata": {},
   "source": [
    "The code executes much more quickly than before, because we are only taking five proposal samples to generate each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63630911",
   "metadata": {},
   "source": [
    "We compare this to the original algorithm that used the default proposal, for\n",
    "the same \"amount of computation\" of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76507c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_inference(measurements, scene, start, computation_amt=5, samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecedcf",
   "metadata": {},
   "source": [
    "We should see that the results are somewhat more accurate using the\n",
    "data-driven proposal.  In particular, there is less probability mass in the\n",
    "lower left corner when using the data-driven proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c7dfd",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<!-- # BEGIN ANSWER KEY 2A.5\n",
    "\n",
    "function do_inference_data_driven(\n",
    "        dest_proposal::GenerativeFunction,\n",
    "        scene::Scene, dt::Float64,\n",
    "        num_ticks::Int, planner_params::PlannerParams,\n",
    "        start::Point, measurements::Vector{Point}, \n",
    "        amount_of_computation::Int)\n",
    "    \n",
    "    observations = Gen.choicemap((:start_x, start.x), (:start_y, start.y))\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => (i, :x)] = m.x\n",
    "        observations[:meas => (i, :y)] = m.y\n",
    "    end\n",
    "    \n",
    "    # invoke the variant of importance_resampling \n",
    "    # that accepts a custom proposal (dest_proposal).\n",
    "    # the arguments to the custom proposal are (measurements, scene)\n",
    "    (trace, _) = Gen.importance_resampling(agent_model, (scene, dt, num_ticks, planner_params), observations, \n",
    "        dest_proposal, (measurements, scene), amount_of_computation)\n",
    "    \n",
    "    return trace\n",
    "end;\n",
    "\n",
    "function visualize_data_driven_inference(measurements, scene, start, proposal; amt_computation=50, samples=1000)\n",
    "    visualize() do \n",
    "      for i=1:samples\n",
    "          trace = do_inference_data_driven(proposal, \n",
    "              scene, dt, num_ticks, planner_params, start, measurements, amt_computation)\n",
    "          draw_dest(scene, Point(trace[:dest_x], trace[:dest_y]))\n",
    "      end\n",
    "        draw_scene(scene)\n",
    "        draw_start(scene, start)\n",
    "        draw_measurements(scene, measurements)\n",
    "    end\n",
    "end;\n",
    "\n",
    "# END ANSWER KEY -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d1798",
   "metadata": {},
   "source": [
    "## 4. Training the parameters of a data-driven proposal <a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc0e30",
   "metadata": {},
   "source": [
    "Our choice of the `score_high` value of 5. was somewhat arbitrary. To use\n",
    "more informed value, we can make `score_high` into a [*trainable\n",
    "parameter*](https://www.gen.dev/docs/stable/ref/modeling/dml/#trainable_parameters_modeling)\n",
    "of the generative function. Below, we write a new version of the proposal\n",
    "function that makes `score_high` trainable. However, the optimization\n",
    "algorithms we will use for training work best with *unconstrained* parameters\n",
    "(parameters that can take any value on the real line), but `score_high` must\n",
    "be positive. Therefore, we introduce an unconstrained trainable parameter\n",
    "mamed `log_score_high`, and use `exp()` to ensure that `score_high` is\n",
    "positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function custom_dest_proposal_trainable(measurements::Vector{Point}, scene::Scene)\n",
    "\n",
    "    @param log_score_high::Float64\n",
    "    \n",
    "    x_first = measurements[1].x\n",
    "    x_last = measurements[end].x\n",
    "    y_first = measurements[1].y\n",
    "    y_last = measurements[end].y\n",
    "    \n",
    "    # sample dest_x\n",
    "    x_probs = compute_bin_probs(num_x_bins, scene.xmin, scene.xmax, x_first, x_last, exp(log_score_high))\n",
    "    x_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_x_bins+1))\n",
    "    dest_x ~ piecewise_uniform(x_bounds, x_probs)\n",
    "    \n",
    "    # sample dest_y\n",
    "    y_probs = compute_bin_probs(num_y_bins, scene.ymin, scene.ymax, y_first, y_last, exp(log_score_high))\n",
    "    y_bounds = collect(range(scene.ymin, stop=scene.ymax, length=num_y_bins+1))\n",
    "    dest_y ~ piecewise_uniform(y_bounds, y_probs)\n",
    "    \n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bdb38",
   "metadata": {},
   "source": [
    "We initialize the value of `score_high` to 1. For this value, our custom\n",
    "proposal gives a uniform distribution, and is the same as the default\n",
    "proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde86899",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen.init_param!(custom_dest_proposal_trainable, :log_score_high, 0.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589342d",
   "metadata": {},
   "source": [
    "Let's visualize the proposed distribution prior to training to confirm that\n",
    "it is a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_custom_destination_proposal(measurements, start, custom_dest_proposal_trainable, num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcac179",
   "metadata": {},
   "source": [
    "Now, we train the generative function. First, we will require a\n",
    "data-generator that generates the training data. The data-generator is a\n",
    "function of no arguments that returns a tuple of the form `(inputs, constraints)`. \n",
    "The `inputs` are the arguments to the generative function\n",
    "being trained, and the `constraints` contains the desired values of random\n",
    "choices made by the function for those arguments. For the training\n",
    "distribution, we will use the distribution induced by the generative model\n",
    "(`agent_model`), restricted to cases where planning actually succeeded. When\n",
    "planning failed, the agent just stays at the same location for all time, and\n",
    "we won't worry about tuning our proposal for that case. The training\n",
    "procedure will attempt to maximize the expected conditional log probablity\n",
    "(density) that the proposal function generates the constrained values,\n",
    "when run on the arguments. \n",
    "Note that this is an *average case* objective function --- the resulting proposal \n",
    "distribution may perform better on some data sets than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function data_generator()\n",
    "    \n",
    "    # since these names are used in the global scope, explicitly declare it\n",
    "    # local to avoid overwriting the global variable\n",
    "    local measurements\n",
    "    local choices\n",
    "    \n",
    "    # obtain an execution of the model where planning succeeded\n",
    "    done = false\n",
    "    while !done\n",
    "        (choices, _, retval) = Gen.propose(agent_model, (scene, dt, num_ticks, planner_params))\n",
    "        (planning_failed, maybe_path) = retval       \n",
    "        done = !planning_failed\n",
    "    end\n",
    "\n",
    "    # construct arguments to the proposal function being trained\n",
    "    measurements = [Point(choices[:meas => (i, :x)], choices[:meas => (i, :y)]) for i=1:num_ticks]\n",
    "    inputs = (measurements, scene)\n",
    "    \n",
    "    # construct constraints for the proposal function being trained\n",
    "    constraints = Gen.choicemap()\n",
    "    constraints[:dest_x] = choices[:dest_x]\n",
    "    constraints[:dest_y] = choices[:dest_y]\n",
    "    \n",
    "    return (inputs, constraints)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba6591",
   "metadata": {},
   "source": [
    "Next, we choose type of optimization algorithm we will use for training. Gen\n",
    "supports a set of gradient-based optimization algorithms (see [Optimizing\n",
    "Trainable\n",
    "Parameters](https://www.gen.dev/docs/stable/ref/inference/parameter_optimization/)).\n",
    "Here we will use gradient descent with a fixed step size of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = Gen.ParamUpdate(Gen.FixedStepGradientDescent(0.001), custom_dest_proposal_trainable);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5158f4",
   "metadata": {},
   "source": [
    "Finally, we use the\n",
    "[`Gen.train!`](https://probcomp.github.io/Gen/dev/ref/inference/#Gen.train!)\n",
    "method to actually do the training.\n",
    "\n",
    "For each epoch, `Gen.train!` makes `epoch_size` calls to the data-generator\n",
    "to construct a batch of training data for that epoch. Then, it iteratively\n",
    "selects `num_minibatch` subsets of the epoch training data, each of size\n",
    "`100`, and applies the update once per minibatch. At the end of the epoch, it\n",
    "generates another batch of evaluation data (of size `evaluation_size`) which\n",
    "it uses to estimate the objective function (the expected conditional log\n",
    "likelihood under the data-generating distribution).\n",
    "\n",
    "Here, we are running 200 gradient-descent updates, where each update is using\n",
    "a gradient estimate obtained from 100 training examples. The method prints\n",
    "the estimate of the objective function after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time scores = Gen.train!(custom_dest_proposal_trainable, data_generator, update,\n",
    "    num_epoch=200, epoch_size=100, num_minibatch=1, minibatch_size=100, evaluation_size=100, verbose=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plot(scores,\n",
    "    xlabel=\"Iterations of stochastic gradient descent\",\n",
    "    ylabel=\"Estimate of expected\\nconditional log probability density\", \n",
    "    label=nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc923a6",
   "metadata": {},
   "source": [
    "We can read out the new value for `score_high`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdefb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(exp(Gen.get_param(custom_dest_proposal_trainable, :log_score_high)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de379c",
   "metadata": {},
   "source": [
    "We see that the optimal value of the parameter is indeed larger than our\n",
    "initial guess. This validates that the heuristic is indeed a useful one. We\n",
    "visualize the proposal distribution below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a09e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_custom_destination_proposal(\n",
    "    measurements, start, custom_dest_proposal_trainable, \n",
    "    num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1faf35b",
   "metadata": {},
   "source": [
    "We can visualize the results of inference, using this newly trained proposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c397232",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(\n",
    "    measurements, scene, start, custom_dest_proposal_trainable,\n",
    "    amt_computation=5, samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(\n",
    "    measurements, scene, start, custom_dest_proposal_trainable,\n",
    "    amt_computation=10, samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7ed8",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d64bff",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Can you devise a data-driven proposal for the speed of the agent? If so, would you\n",
    "expect it to work equally well on all data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985ca7c",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dcaab",
   "metadata": {},
   "source": [
    "## 5. Writing and training a deep learning based data-driven proposal <a name=\"deep\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221f4de",
   "metadata": {},
   "source": [
    "The heuristic data-driven proposal above gave some improvement in efficiency,\n",
    "but it was very simple. One way of constructing complex data-driven proposals\n",
    "is to parametrize the proposal with a deep neural network or use another\n",
    "class of high-capacity machine learning model (e.g. random forest). Here, we\n",
    "will will write a data-driven proposal for the destination of the agent that\n",
    "uses deep neural networks. In this section, we do everything manually, without\n",
    "the aid of neural network libraries. We also provide an [extension to the tutorial](#) that\n",
    "shows how to use PyTorch to make this process a lot easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce60f36",
   "metadata": {},
   "source": [
    "First, we define a sigmoid function for the nonlinearity in our networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinearity(x) = 1.7159 * tanh.(x * 0.66666);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6c4d9",
   "metadata": {},
   "source": [
    "We will use a deep neural network with two hidden layers that takes as input\n",
    "x- and y- coordinates of the first and last measurement (4 values) and\n",
    "produces as output a vector of un-normalized probabilities, one for each bin\n",
    "of the x-dimension. We will later sample `:dest_x` from this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dest_x_neural_net(nn_params, x_first::Real, y_first::Real, x_last::Real, y_last::Real)\n",
    "    (W1, b1, W2, b2, W3, b3) = nn_params\n",
    "    input_layer = [x_first, y_first, x_last, y_last]\n",
    "    hidden_layer_1 = nonlinearity(W1 * input_layer .+ b1)\n",
    "    hidden_layer_2 = nonlinearity(W2 * hidden_layer_1 .+ b2)\n",
    "    output_layer = exp.(W3 * hidden_layer_2 .+ b3)\n",
    "    return output_layer\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561e700",
   "metadata": {},
   "source": [
    "After sampling the value of `:dest_x`, we will use a second deep neural\n",
    "network with the same structure to sample `:dest_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8025aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dest_y_neural_net(nn_params, x_first::Real, y_first::Real, x_last::Real, y_last::Real)#, dest_x::Real)\n",
    "    (W1, b1, W2, b2, W3, b3) = nn_params\n",
    "    input_layer = [x_first, y_first, x_last, y_last]\n",
    "    hidden_layer_1 = nonlinearity(W1 * input_layer .+ b1)\n",
    "    hidden_layer_2 = nonlinearity(W2 * hidden_layer_1 .+ b2)\n",
    "    output_layer = exp.(W3 * hidden_layer_2 .+ b3)\n",
    "    return output_layer\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10e98d8",
   "metadata": {},
   "source": [
    "Now that we have defined our neural networks, we define our new proposal.\n",
    "This generative function has a number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_coord(coord, min, max) = (coord / (max - min)) - 0.5\n",
    "\n",
    "@gen function custom_dest_proposal_neural(measurements::Vector{Point}, scene::Scene)\n",
    "    @param x_W1::Matrix{Float64}\n",
    "    @param x_b1::Vector{Float64}\n",
    "    @param x_W2::Matrix{Float64}\n",
    "    @param x_b2::Vector{Float64}\n",
    "    @param x_W3::Matrix{Float64}\n",
    "    @param x_b3::Vector{Float64}\n",
    "    \n",
    "    @param y_W1::Matrix{Float64}\n",
    "    @param y_b1::Vector{Float64}\n",
    "    @param y_W2::Matrix{Float64}\n",
    "    @param y_b2::Vector{Float64}\n",
    "    @param y_W3::Matrix{Float64}\n",
    "    @param y_b3::Vector{Float64}\n",
    "    \n",
    "    num_x_bins = length(x_b3)\n",
    "    num_y_bins = length(y_b3)\n",
    "    \n",
    "    # scale inputs to be in the range [-0.5, 0.5]\n",
    "    x_first = scale_coord(measurements[1].x, scene.xmin, scene.xmax)\n",
    "    x_last = scale_coord(measurements[end].x, scene.xmin, scene.xmax)\n",
    "    y_first = scale_coord(measurements[1].y, scene.ymin, scene.ymax)\n",
    "    y_last = scale_coord(measurements[end].y, scene.ymin, scene.ymax)\n",
    "    \n",
    "    # sample dest_x\n",
    "    x_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_x_bins+1))\n",
    "    x_probs = dest_x_neural_net((x_W1, x_b1, x_W2, x_b2, x_W3, x_b3), x_first, y_first, x_last, y_last)\n",
    "    dest_x ~ piecewise_uniform(x_bounds, x_probs / sum(x_probs))\n",
    "    \n",
    "    # sample dest_y\n",
    "    y_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_y_bins+1))\n",
    "    y_probs = dest_y_neural_net((y_W1, y_b1, y_W2, y_b2, y_W3, y_b3), x_first, y_first, x_last, y_last)\n",
    "    dest_y ~ Gen.piecewise_uniform(y_bounds, y_probs / sum(y_probs))\n",
    "    \n",
    "    return nothing\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbd801",
   "metadata": {},
   "source": [
    "We will use 50 hidden units in each of the layers of the two networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_1 = 50\n",
    "num_hidden_2 = 50;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3364661",
   "metadata": {},
   "source": [
    "Next, we initialize the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b57fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Random\n",
    "Random.seed!(3)\n",
    "\n",
    "init_weight(shape...) = (1. / sqrt(shape[2])) * randn(shape...)\n",
    "\n",
    "init_x_W1 = init_weight(num_hidden_1, 4)\n",
    "init_x_W2 = init_weight(num_hidden_2, num_hidden_1)\n",
    "init_x_W3 = init_weight(num_x_bins, num_hidden_2)\n",
    "\n",
    "# set parameters for dest_x_neural_net predictor network\n",
    "init_param!(custom_dest_proposal_neural, :x_W1, init_x_W1)\n",
    "init_param!(custom_dest_proposal_neural, :x_b1, zeros(num_hidden_1))\n",
    "init_param!(custom_dest_proposal_neural, :x_W2, init_x_W2)\n",
    "init_param!(custom_dest_proposal_neural, :x_b2, zeros(num_hidden_2))\n",
    "init_param!(custom_dest_proposal_neural, :x_W3, init_x_W3)\n",
    "init_param!(custom_dest_proposal_neural, :x_b3, zeros(num_x_bins))\n",
    "\n",
    "init_y_W1 = init_weight(num_hidden_1, 4)\n",
    "init_y_W2 = init_weight(num_hidden_2, num_hidden_1)\n",
    "init_y_W3 = init_weight(num_x_bins, num_hidden_2)\n",
    "\n",
    "# set parameters for dest_y_neural_net predictor network\n",
    "init_param!(custom_dest_proposal_neural, :y_W1, init_y_W1)\n",
    "init_param!(custom_dest_proposal_neural, :y_b1, zeros(num_hidden_1))\n",
    "init_param!(custom_dest_proposal_neural, :y_W2, init_y_W2)\n",
    "init_param!(custom_dest_proposal_neural, :y_b2, zeros(num_hidden_2))\n",
    "init_param!(custom_dest_proposal_neural, :y_W3, init_y_W3)\n",
    "init_param!(custom_dest_proposal_neural, :y_b3, zeros(num_y_bins));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e5034",
   "metadata": {},
   "source": [
    "Now, we visualize the proposal distribution prior to training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e898a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_custom_destination_proposal(measurements, start, custom_dest_proposal_neural, num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3f7ad",
   "metadata": {},
   "source": [
    "It looks like the initial distribution is roughly uniform, like the default\n",
    "proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54efb26",
   "metadata": {},
   "source": [
    "Now we train the network stochastic gradient descent with a fixed step size\n",
    "of 0.001 that is shared among all of the trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = Gen.ParamUpdate(Gen.FixedStepGradientDescent(0.001), custom_dest_proposal_neural);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ec578-99e4-49e9-9e28-b45fd22bd434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using JLD2\n",
    "# @time scores = Gen.train!(custom_dest_proposal_neural, data_generator, update,\n",
    "#     num_epoch=50, epoch_size=100, num_minibatch=100, minibatch_size=100,\n",
    "#     evaluation_size=1000, verbose=true);\n",
    "    \n",
    "# let data = Dict()\n",
    "#     for name in [:x_W1, :x_b1, :x_W2, :x_b2, :x_W3, :x_b3, :y_W1, :y_b1, :y_W2, :y_b2, :y_W3, :y_b3]\n",
    "#         data[(:param, name)] = Gen.get_param(custom_dest_proposal_neural, name)\n",
    "#     end\n",
    "#     data[:scores] = scores\n",
    "#     save(\"params/custom_dest_proposal_neural_trained.jld2\", \"data\", data)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b25ff1",
   "metadata": {},
   "source": [
    "We use 50 epochs of training. In each epoch, we generate 100 training\n",
    "examples, and we apply 100 gradient updates, where each update is based on\n",
    "the gradient estimate obtained from a random set of 100 of the trainable\n",
    "examples. At the end of each epoch, we estimate the objective function value\n",
    "using 10000 freshly sampled examples. This process takes about 10 minutes to\n",
    "run on a typical laptop CPU, so we have precomputed the results for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635ef19",
   "metadata": {},
   "source": [
    "```julia\n",
    "using JLD2\n",
    "@time scores = Gen.train!(custom_dest_proposal_neural, data_generator, update,\n",
    "    num_epoch=50, epoch_size=100, num_minibatch=100, minibatch_size=100,\n",
    "    evaluation_size=1000, verbose=true);\n",
    "    \n",
    "let data = Dict()\n",
    "    for name in [:x_W1, :x_b1, :x_W2, :x_b2, :x_W3, :x_b3, :y_W1, :y_b1, :y_W2, :y_b2, :y_W3, :y_b3]\n",
    "        data[(:param, name)] = Gen.get_param(custom_dest_proposal_neural, name)\n",
    "    end\n",
    "    data[:scores] = scores\n",
    "    save(\"params/custom_dest_proposal_neural_trained.jld2\", \"data\", data)\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1ee9c",
   "metadata": {},
   "source": [
    "We load the results here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce344f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JLD2\n",
    "scores = let data = JLD2.load(\"params/custom_dest_proposal_neural_trained.jld2\", \"data\")\n",
    "    for name in [:x_W1, :x_b1, :x_W2, :x_b2, :x_W3, :x_b3, :y_W1, :y_b1, :y_W2, :y_b2, :y_W3, :y_b3]\n",
    "        Gen.init_param!(custom_dest_proposal_neural, name, data[(:param, name)])\n",
    "    end\n",
    "    data[:scores]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c98bed",
   "metadata": {},
   "source": [
    "We plot the estimate of the objective function over epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5194ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(scores,\n",
    "    xlabel=\"Epochs\", \n",
    "    ylabel=\"Estimate of expected\\nconditional log probability density\", \n",
    "    label=nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67874b8",
   "metadata": {},
   "source": [
    "Below, we visualize the trained proposal distribution for our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11314116",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_custom_destination_proposal(measurements, start, custom_dest_proposal_neural, num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dad02b",
   "metadata": {},
   "source": [
    "If we run inference with `amt_computation` set to 5, we see that the inferred distribution reflects the bias of the proposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(measurements, scene, start, custom_dest_proposal_neural,\n",
    "    amt_computation=5, samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93160538",
   "metadata": {},
   "source": [
    "As we increase the amount of computation, the effect of the proposal's bias\n",
    "is reduced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59310342",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(measurements, scene, start, custom_dest_proposal_neural,\n",
    "    amt_computation=50, samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddbf50",
   "metadata": {},
   "source": [
    "This bias-correction is more noticeable the more computation we use (though here we only draw 100 approximate posterior samples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8688626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data_driven_inference(measurements, scene, start, custom_dest_proposal_neural,\n",
    "    amt_computation=1000, samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccfb94",
   "metadata": {},
   "source": [
    "This example highlights an important aspect of importance sampling: it not\n",
    "only _upweights_ guesses that explain the data well; it also _downweights_ guesses\n",
    "that are too high-probability under the proposal distribution. That is, if a proposal\n",
    "is heavily biased toward one region of the state space, all guesses in that region will\n",
    "be downweighted accordingly. That's why, even though (a) guesses in the left and right halves\n",
    "of the room are equally likely, and (b) the\n",
    "proposal stongly prefers the left half of the room, the importance sampling algorithm\n",
    "samples roughly the same number of points in each half of the room.\n",
    "\n",
    "In the limit of infinite computation, the distribution induced by importance sampling\n",
    "converges to the true posterior, independent of the proposal. Indeed, using the\n",
    "generic proposal with a high amount of computation produces very similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ff845",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_inference(measurements, scene, start; computation_amt=1000, samples=100)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "jl:light,ipynb"
  },
  "kernelspec": {
   "display_name": "Algorithms of the Mind (Julia) 1.9.2",
   "language": "julia",
   "name": "atom-jl-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
